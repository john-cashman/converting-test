imports:
  embedding: ./embedding.yml
  tts: ./tts.yml

types:
  VoiceId:
    type: string
    docs: |
      The ID of the voice.

  BaseVoiceId:
    type: VoiceId
    docs: |
      Pull in features from a base voice, used for features like voice mixing.

  Voice:
    properties:
      id: VoiceId
      is_owner:
        type: boolean
        docs: |
          Whether the current user is the owner of the voice.
      name: &name
        type: string
        docs: |
          The name of the voice.
      description: &description
        type: string
        docs: |
          The description of the voice.
      created_at:
        type: datetime
        docs: |
          The date and time the voice was created.
      embedding:
        type: optional<embedding.Embedding>
        docs: |
          The vector embedding of the voice. Only included when `expand` includes `embedding`.
      is_starred:
        type: optional<boolean>
        docs: |
          Whether the current user has starred the voice. Only included when `expand` includes `is_starred`.
      language: tts.SupportedLanguage

  VoiceMetadata:
    properties:
      id: VoiceId
      user_id:
        type: string
        docs: |
          The ID of the user who owns the voice.
      is_public:
        type: boolean
        docs: |
          Whether the voice is publicly accessible.
      name: &name
        type: string
        docs: |
          The name of the voice.
      description: &description
        type: string
        docs: |
          The description of the voice.
      created_at:
        type: datetime
        docs: |
          The date and time the voice was created.
      language: tts.SupportedLanguage

  GetVoicesResponse:
    properties:
      data:
        type: list<Voice>
        docs: The paginated list of Voices.
      has_more:
        type: boolean
        docs: Whether there are more Voices to fetch (using `starting_after=id`, where id is the ID of the last Voice in the current response).
      next_page:
        type: optional<VoiceId>
        docs: (Deprecated - use the id of the last Voice in the current response instead.) An ID that can be passed as `starting_after` to get the next page of Voices.


  CreateVoiceRequest:
    properties:
      name: *name
      description: *description
      embedding: embedding.Embedding
      language: optional<tts.SupportedLanguage>
      base_voice_id: optional<BaseVoiceId>

  UpdateVoiceRequest:
    properties:
      name: *name
      description: *description

  LocalizeTargetLanguage:
    docs: |
      Target language to localize the voice to.

      Options: English (en), German (de), Spanish (es), French (fr), Japanese (ja), Portuguese (pt), Chinese (zh), Hindi (hi), Italian (it), Korean (ko), Dutch (nl), Polish (pl), Russian (ru), Swedish (sv), Turkish (tr).
    enum:
      - en
      - de
      - es
      - fr
      - ja
      - pt
      - zh
      - hi
      - it
      - ko
      - nl
      - pl
      - ru
      - sv
      - tr

  LocalizeEnglishDialect:
    enum:
      - au
      - in
      - so
      - uk
      - us

  LocalizeFrenchDialect:
    enum:
      - eu
      - ca

  LocalizeSpanishDialect:
    enum:
      - mx
      - pe

  LocalizePortugueseDialect:
    enum:
      - br
      - eu

  LocalizeDialect:
    discriminated: false
    union:
      - type: LocalizeEnglishDialect
        display-name: English dialect
        docs: |
          Only available when language is set to English (`en`). Options: Australian (`au`), Indian (`in`), Southern (`so`), British (`uk`), or American (`us`).
      - type: LocalizeSpanishDialect
        display-name: Spanish dialect
        docs: |
          Only available when language is set to Spanish (`es`). Options: Latin American (`mx`) and Peninsular (`pe`).
      - type: LocalizePortugueseDialect
        display-name: Portuguese dialect
        docs: |
          Only available when language is set to Portuguese (`pt`). Options: Brazilian (`br`) and European Portuguese (`eu`).
      - type: LocalizeFrenchDialect
        display-name: French dialect
        docs: |
          Only available when language is set to French (`fr`). Options: Standard Parisian/Metropolitan (`eu`) and Canadian (`ca`).
    docs: |
      The dialect to localize to. Only supported for English (`en`), Spanish (`es`), Portuguese (`pt`), and French (`fr`).

  GenderPresentation:
    enum:
      - masculine
      - feminine
      - gender_neutral

  Gender:
    enum:
      - male
      - female

  VoiceExpandOptions:
    enum:
      - embedding
      - is_starred

  LocalizeVoiceRequest:
    properties:
      voice_id:
        type: string
        docs: |
          The ID of the voice to localize.
      name:
        type: string
        docs: |
          The name of the new localized voice.
      description:
        type: string
        docs: |
          The description of the new localized voice.
      language: LocalizeTargetLanguage
      original_speaker_gender: Gender
      dialect: optional<LocalizeDialect>

  EmbeddingResponse:
    properties:
      embedding: embedding.Embedding

  MixVoicesRequest:
    properties:
      voices: list<MixVoiceSpecifier>

  Weight:
    type: double
    docs: |
      The weight of the voice or embedding in the mix. If weights do not sum to 1, they will be normalized.

  IdSpecifier:
    properties:
      id: VoiceId
      weight: Weight

  EmbeddingSpecifier:
    properties:
      embedding: embedding.Embedding
      weight: Weight

  MixVoiceSpecifier:
    discriminated: false
    union:
      - IdSpecifier
      - EmbeddingSpecifier

  CloneMode:
    enum:
      - similarity
      - stability

service:
  base-path: /voices
  auth: true
  endpoints:
    list:
      path: /
      method: GET
      display-name: List Voices
      request:
        name: GetVoicesRequest
        query-parameters:
          limit:
            type: optional<integer>
            default: 10
            docs: The number of Voices to return per page, ranging between 1 and 100.
          starting_after:
            type: optional<string>
            docs: |
              A cursor to use in pagination. `starting_after` is a Voice ID that defines your
              place in the list. For example, if you make a /voices request and receive 100
              objects, ending with `voice_abc123`, your subsequent call can include
              `starting_after=voice_abc123` to fetch the next page of the list.
          ending_before:
            type: optional<string>
            docs: |
              A cursor to use in pagination. `ending_before` is a Voice ID that defines your
              place in the list. For example, if you make a /voices request and receive 100
              objects, starting with `voice_abc123`, your subsequent call can include
              `ending_before=voice_abc123` to fetch the previous page of the list.
          is_owner:
            type: optional<boolean>
            docs: Whether to only return voices owned by the current user.
          is_starred:
            type: optional<boolean>
            docs: Whether to only return starred voices.
          gender:
            type: optional<GenderPresentation>
            docs: The gender presentation of the voices to return.
          expand[]:
            type: optional<list<VoiceExpandOptions>>
            docs: |
              Additional fields to include in the response.
      response: GetVoicesResponse
      pagination:
        cursor: $request.starting_after
        next_cursor: $response.next_page
        results: $response.data

    clone:
      path: /clone
      method: POST
      display-name: Clone Voice
      docs: |
        Clone a voice from an audio clip. This endpoint has two modes, stability and similarity.

        Similarity mode clones are more similar to the source clip, but may reproduce background noise. For these, use an audio clip about 5 seconds long.

        Stability mode clones are more stable, but may not sound as similar to the source clip. For these, use an audio clip 10-20 seconds long.
      request:
        name: CloneVoiceRequest
        body:
          properties:
            clip:
              type: file
              docs: |
                The audio clip to clone. For stability mode, the clip should be 10-20 seconds long. For similarity mode, the clip should be about 5 seconds long.
            name:
              type: string
              docs: |
                The name of the voice.
            description:
              type: optional<string>
              docs: |
                A description for the voice.
            language:
              type: tts.SupportedLanguage
              docs: |
                The language of the voice.
            mode:
              type: CloneMode
              docs: |
                Tradeoff between similarity and stability. Similarity clones sound more like the source clip, but may reproduce background noise. Stability clones always sound like a studio recording, but may not sound as similar to the source clip.
            enhance:
              type: optional<boolean>
              docs: |
                Whether to apply AI enhancements to the clip to reduce background noise. This leads to cleaner generated speech at the cost of reduced similarity to the source clip.
            base_voice_id:
              type: optional<VoiceId>
              docs: |
                Optional base voice ID that the cloned voice is derived from.
      response: VoiceMetadata
      examples:
        - name: Stability
          request:
            # clip: file
            name: "A high-stability cloned voice"
            description: "Copied from Cartesia docs"
            mode: stability
            language: en
          response:
            body:
              id: "df076429-66c6-4f3e-b98b-aee4e2c925ab"
              user_id: "482aa35e-d86c-42a4-b818-7bdcfe40a858"
              is_public: false
              name: "A high-stability cloned voice"
              description: "Copied from Cartesia docs"
              created_at: "2024-11-13T07:06:22.476564Z"
              language: en
        - name: Similarity
          request:
            # clip: file
            name: "A high-similarity cloned voice"
            description: "Copied from Cartesia docs"
            mode: similarity
            language: en
          response:
            body:
              id: "40248dd5-bfe9-48e2-93f7-ea3f9d5c7f72"
              user_id: "482aa35e-d86c-42a4-b818-7bdcfe40a858"
              is_public: false
              name: "A high-similarity cloned voice"
              description: "Copied from Cartesia docs"
              created_at: "2024-11-13T07:06:22.476564Z"
              language: en

    delete:
      path: /{id}
      method: DELETE
      display-name: Delete Voice
      path-parameters:
        id: VoiceId

    update:
      path: /{id}
      method: PATCH
      display-name: Update Voice
      path-parameters:
        id: VoiceId
      request: UpdateVoiceRequest
      response: Voice

    get:
      path: /{id}
      method: GET
      display-name: Get Voice
      path-parameters:
        id: VoiceId
      response: Voice

    localize:
      path: /localize
      method: POST
      display-name: Localize Voice
      docs: |
        Create a new voice from an existing voice localized to a new language and dialect.
      request: LocalizeVoiceRequest
      response: VoiceMetadata
      examples:
        - name: Localize Voice
          request:
            voice_id: "694f9389-aac1-45b6-b726-9d9369183238"
            name: "Sarah Peninsular Spanish"
            description: "Sarah Voice in Peninsular Spanish"
            language: es
            original_speaker_gender: female
            dialect: pe
          response:
            body:
              id: "8f7d3c2e-1a2b-3c4d-5e6f-7g8h9i0j1k2l"
              user_id: "user_id"
              is_public: false
              name: "Sarah Peninsular Spanish"
              description: "Sarah Voice in Peninsular Spanish"
              created_at: "2024-03-15T10:30:00.000Z"
              language: es

    mix:
      path: /mix
      method: POST
      display-name: Mix Voices
      request: MixVoicesRequest
      response: EmbeddingResponse

    create:
      path: /
      method: POST
      display-name: Create Voice
      docs: |
        Create voice from raw features. If you'd like to clone a voice from an audio file, please use Clone Voice instead.
      request: CreateVoiceRequest
      response: Voice
